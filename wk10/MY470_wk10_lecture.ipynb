{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MY470 Computer Programming\n",
    "# Searching and Sorting Algorithms\n",
    "### Week 10 Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem Set 5 takes place in class tomorrow!\n",
    "\n",
    "* Come to your class. Don't be late. \n",
    "* **7 questions, 25 min long**\n",
    "  * Give **Big-O for time complexity** and explain reasoning in 1-2 sentences.\n",
    "  * Last 2 questions also ask you to write a simple function (~3 lines of code each)\n",
    "* If you miss class and have not informed us **in advance** with a valid reason, we will mark your submission as **no attempt** and assign 0 to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "We will practice thinking about algorithm design and complexity analysis:\n",
    "\n",
    "* Search algorithms\n",
    "    * Linear search\n",
    "    * Binary search\n",
    "* Sorting algorithms\n",
    "    * Bubble sort\n",
    "    * Selection sort\n",
    "    * Insertion sort\n",
    "    * Merge sort\n",
    "* Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- revisit binary search (called it binary search)\n",
    "- sorting algorithms in the order of their efficiency(but the first three all n**2, only merge sort is O(n log n))\n",
    "- hashing\n",
    "    - might have encountered it as an error\n",
    "    - when trying to put certain values into dict or set, saying something like list is non-hashable element, now understand where this comes from\n",
    "    - how to implement data structures where you can look up items in O(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Searching\n",
    "\n",
    "![Searching](figs/searching.jpg \"Searching\")\n",
    "\n",
    "* The goal is to find a specific item in a collection of items\n",
    "* The answer could be `True` or `False`, or alternatively, the precise location of the item\n",
    "* In Python, search with `in`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in to check whether element in the list\n",
    "- could also get the precise index of where the element is in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 in [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear/Sequential Search\n",
    "\n",
    "* Visit each item in the collection in order until you discover the item or until you run out of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def linear_search(ls, e):\n",
    "    \"\"\"Assume ls is a list.\n",
    "    Return True if e is in ls, False otherwise.\n",
    "    \"\"\"\n",
    "    for i in range(len(ls)):\n",
    "        if ls[i]==e:\n",
    "            return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in order to find whether element is in there, no other way but to visit every element in the list until we find it\n",
    "    - iterating over each item in the list (or other data type)\n",
    "- using indexing might not be the best option\n",
    "    - can easily fix the function to tell us where the element is instead of just true or false\n",
    "- **Time complexity: O(n) where n is the length of the list ls**\n",
    "    - the longer our list is the more time we require to go through the entire list\n",
    "- space complexity: no new variables created, thus constant O(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Exercise 1: What is the time and space complexity of linear search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Binary Search\n",
    "\n",
    "*Example of divide and conquer strategy – break the problem into smaller pieces, solve the smaller pieces, and then reassemble to get the result*\n",
    "\n",
    "\n",
    "* Assume search space is sorted\n",
    "* Start from the middle\n",
    "    * If the item is the one we are searching for, we are done\n",
    "    * If the item is larger than the one we are searching for, eliminate the upper half and repeat the search in the lower half\n",
    "    * If the item is smaller than the one we are searching for, eliminate the lower half and repeat the search in the upper half\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **we can do better than sequential serach under one condition: the data is sorted**\n",
    "- we introduced binary search as bisection search\n",
    "- start form the emiddle, check that element, if that is not the element can assesss whether element is larger or smaller, if larger then ignore everything that is above \n",
    "    - **= divide and conquer strategy**: break complex problem into smaller same type of problems, solve each and reassemble to get the solution\n",
    "    - -> **naturally implemented as a recursive function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Binary Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# binary_search() is called a \"wrapper function\" –\n",
    "# it hides the implementation details\n",
    "def binary_search(ls, e):\n",
    "    \"\"\"Assume ls is a list with its elements in ascending order.\n",
    "    Return True if e is in ls, False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    def b_search(ls, e, low, high):\n",
    "        # Decrement high - low\n",
    "        if high==low: # only one item left\n",
    "            return ls[low]==e\n",
    "        mid = (low + high)//2\n",
    "        \n",
    "        # Check if the item is at the midpoint\n",
    "        if ls[mid]==e:\n",
    "            return True\n",
    "        # If the item is smaller than the midpoint, search in the lower half \n",
    "        elif ls[mid] > e:\n",
    "            if low==mid: # no items left\n",
    "                return False\n",
    "            else:\n",
    "                return b_search(ls, e, low, mid - 1)\n",
    "        # If the item is larger than the midpoint, search in the higher half \n",
    "        else:\n",
    "            return b_search(ls, e, mid + 1, high)\n",
    "        \n",
    "    if len(ls)==0:\n",
    "        return False\n",
    "    else:\n",
    "        return b_search(ls, e, 0, len(ls) - 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT:\n",
    "This function performs a binary search, which is an efficient algorithm for finding an element in a **sorted list** by repeatedly dividing the search interval in half.\n",
    "\n",
    "- In each recursive call (or iteration in a non-recursive binary search), the search space is halved.\n",
    "    - After the first step, the search space is n/2\n",
    "    - After the second step, the search space is n/4 and so on\n",
    "- The search space keeps halving until the number of elements left is 1 (or no elements are left to search).\n",
    "- The number of steps (recursive calls) required to reduce the search space from n elements to 1 element is logarithmic in base 2, log n\n",
    "- Thus, the time complexity of binary search is O(log n), where n is the lenght of the list\n",
    "\n",
    "- Space complexity: Space Complexity: The space complexity is O(log n) due to the recursive calls. Each recursive call adds a new frame to the call stack, and since the recursion depth is proportional to the logarithm of the number of elements, the space complexity is also logarithmic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- extra steps to account for not skipping any of the indices\n",
    "- integer dividsion -> we can then use mid as an index\n",
    "- looking for particuar value contained in a list, thus have to be careful with the index to ensure we dont miss anything\n",
    "- outer function = wrapper function\n",
    "    - hides the implementation detail\n",
    "    - the recursive function requires to be specified with an interval but the user should not care how it is implemented, hides implementation details, that is the only purpose it serves\n",
    "    - why specifying arguments for the helper function if not dependent on user input?\n",
    "\n",
    "- **time complexity of binary search: O(log n) or O(e log n) depending on what e is, e lenght of string and n is length of the list**\n",
    "    - At every step, we halve the range in which to look for. If we double the data, we need one more step. \n",
    "    - 2 inputs: ls and e\n",
    "        - only depends on e if e is a string\n",
    "        - when comparing strings, or if e is another list, have to compare every element ~ has a loop in it\n",
    "    - if you want to be more inclusive, have to account for the fact that e could be a string\n",
    "- space copmlexity: recursive function \n",
    "    - when recursive function: at the bottom of recursive tree how many memory threads you have opened up, until we get to the bottom of the tree we have log n threads, \n",
    "    - thus here space complexity is also log n, BE CAREFUL WITH SPACE COMPLEXITY FOR RECURSIVE FUNCTIONS\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "log n: at every step halfing the range we are looking for, if we double the data, we only need one extra step, the steps at which we are reducing are larger than ... where n is the length of the list\n",
    "    - search does not depend on e unless E IS A STRING, when comparing string to another string or if another list, have to compare every element in this object, then it has a loop in it too\n",
    "    - without makign assumption that e is particular type, techncially have to also express it as a function of e, if it has its own sub elemetns, big O of n*e where n is lenght of list and e is lenght of element e in cases when e is some kind of sequence \n",
    "    - BECAUSE NO SPECIFICAOITN OF WHAT E IS, n * log n, log n attemps where we compare the length of e thus O(n*log n)\n",
    "    - NO AMBIGUITIES IN THE QUIZ\n",
    "    - converse: \n",
    "    - steps are changing, if large data, when halving much larger amount of data removed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Exercise 2: What is the time and space complexity of binary search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When to Sort and Use Binary Search\n",
    "\n",
    "* Best if searching needs to be done many times\n",
    "* For small $n$, the additional cost of sorting is likely not worth it\n",
    "* For large $n$, sorting may be too expensive and ultimately, sequential search may be preferable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- do we do linear search (O(n)) or sort (n log n) and then do binary search (log n except if e has internal structure)?\n",
    "    - depends on application and data (how large the data, how many sorts if the data changes, how many searches)\n",
    "    - linear serach is good enough most of the time\n",
    "    - if we search a lotof times and the data does not change, then makes sense to sort and then do quick searches with log n\n",
    "    - if the data keeps changing, then you have to keep on sorting\n",
    "    - if onyl couple of searches, then linear good enough\n",
    "- if lots of searches, better way to do this with hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sorting\n",
    "\n",
    "![Sorting](figs/sorting.jpg \"Sorting\")\n",
    "\n",
    "* The goal is to place items from a collection in some kind of order\n",
    "* Sorting requires two operations:\n",
    "    * Compare values\n",
    "    * Exchange values if they are not in the correct order\n",
    "* **The efficiency of a sorting algorithm depends on the total number of comparisons and exchanges**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **List.sort: in place, without creating new list**\n",
    "- **sorted(): call it not just on lists but any kind of sequence or string**\n",
    "    - we get new object of same data type that is sorted\n",
    "- they are in order of runtime efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 1, 2, 4] [1, 2, 3, 4, 5]\n",
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "ls = [3, 5, 1, 2, 4]\n",
    "ls_new = sorted(ls)\n",
    "print(ls, ls_new)\n",
    "\n",
    "ls.sort()\n",
    "print(ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sorting Algorithms\n",
    "\n",
    "* Bubble sort\n",
    "* Selection sort\n",
    "* Insertion sort\n",
    "* Merge sort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bubble Sort\n",
    "\n",
    "![Bubble sort](figs/bubble_sort.jpg \"Bubble sort\")\n",
    "\n",
    "1. Iterate over a list and compare the item at the current position with every item in the remaining sublist; swap the items if necessary to get the correct ordering\n",
    "2. Repeat until no swaps are done\n",
    "\n",
    "[Visualization](https://visualgo.net/bn/sorting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bubble Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- start from beginning, push back the largest element, largest bubble moving through the data until it goes to the end, then the second largest\n",
    "- visualgo.net/en/sorting\n",
    "- code\n",
    "    - starts from the beginning\n",
    "    - compare element where we are with the one that follows, if our current one is larger, then we swap them\n",
    "    - with one line we reassign two values\n",
    "    - reduce the area where we iterate by one every time, the one is already sorted, look at every thing than the last one\n",
    "- time complexity: \n",
    "    - two nested loops, both of them go over some part of the data\n",
    "    - quadratic O(n**2) where n is the lenght of the list ls\n",
    "    - inner one is shorter: keep on looking at shorter segment of the data, have pushed all the larger elements to the back\n",
    "        - ends up being a constant which we ignore?\n",
    "    - a lot of non final swaps: most of the shifting is temporary that we have to do again and again, too many unnecessary operations\n",
    "        - very inefficient in terms of run time\n",
    "- bubble sort is very inefficient, still doable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT:\n",
    "- The outer loop (for passnum in range(len(ls) - 1, 0, -1)) iterates from the last element (len(ls) - 1) down to the second element (1), effectively iterating n−1 times (where n is the length of the list).\n",
    "- The inner loop (for i in range(passnum)) iterates over the unsorted portion of the list. On the first pass, it compares all n−1 elements. On the second pass, it compares n−2 elements, and so on, until it compares just 1 element on the last pass.\n",
    "- Inside the inner loop, if an element at position i is greater than the element at position i+1, the two elements are swapped. This operation is constant-time O(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def bubble_sort(ls):\n",
    "    \"\"\"Assume ls is a list of elements that can be compared using >.\n",
    "    Sort ls in ascending order.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Start from the whole list, reducing towards the front\n",
    "    for passnum in range(len(ls) - 1, 0, -1):\n",
    "        # Consider each of the sublists\n",
    "        for i in range(passnum):\n",
    "            if ls[i] > ls[i + 1]:\n",
    "                # Swap, pushing the larger number to the back\n",
    "                ls[i], ls[i + 1] = ls[i + 1], ls[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Exercise 3: What is the time and space complexity of bubble sort?\n",
    "\n",
    "[Hint](https://www.youtube.com/watch?v=koMpGeZpu4Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selection Sort\n",
    "\n",
    "1. Iterate over a list and look for the largest/smallest item in the remaining sublist\n",
    "2. Swap the item in the current position with the identified item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- iterate over list, look for largest/smallest element, just want to identify it, not swap it, then swap the element \n",
    "- fewer swaps than with bubble sort, first identify what to swap and then do a swap\n",
    "- going through list many times but fewer swaps\n",
    "- code\n",
    "    - inner loop: \n",
    "    - look for the element htat is larger than we have currently recorded as the max position\n",
    "    - if we encounter anything that is larger, we change what we identify as the largest element\n",
    "    - move largest element at the end, then again dont have to look at all elements again\n",
    "- time complexity: grows on the order of n squared\n",
    "    - no diff, still nested loops, one gets shorter and shorter but\n",
    "- more efficient because some of the operations are outside of inner loop, thus we only do them n times rather than n squared\n",
    "    - dont do that many non final swaps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def selection_sort(ls):\n",
    "    \"\"\"Assume ls is a list of elements that can be compared using >.\n",
    "    Sort ls in ascending order.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Consider each position, starting from the back\n",
    "    for pos in range(len(ls) - 1, 0, -1):\n",
    "        max_pos = 0\n",
    "        # Find the largest item in the sublist until this position\n",
    "        for i in range(1, pos + 1):\n",
    "            if ls[i] > ls[max_pos]:\n",
    "                max_pos = i\n",
    "        \n",
    "        # Swap the item at this position with the largest item\n",
    "        ls[pos], ls[max_pos] = ls[max_pos], ls[pos]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT\n",
    "- Outer Loop:\n",
    "    - The outer loop (for pos in range(len(ls) - 1, 0, -1)) iterates through the list from the last position to the second position. \n",
    "    - At each iteration, it selects the largest element in the unsorted part of the list and places it in its correct position.\n",
    "- Inner Loop:\n",
    "    - The inner loop (for i in range(1, pos + 1)) searches through the unsorted part of the list, starting from the beginning up to the current position of pos.\n",
    "    - It compares each element with the current largest element (tracked by max_pos).\n",
    "    - The largest element is stored in max_pos.\n",
    "- Swapping:\n",
    "    - After the inner loop completes, the element at the max_pos (the largest found element in the unsorted part) is swapped with the element at the current pos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Exercise 4: What is the time complexity of selection sort?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Insertion Sort\n",
    "\n",
    "1. Iterate over a list starting from the beginning\n",
    "2. Insert each new item into the previous sublist in order, shifting the positions of larger items by 1\n",
    "\n",
    "In essence, the algorithm maintains a sorted sublist in the lower positions of the list as it progresses one item ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- every element we encounter, go back and put it into its rightful slot in the section we have already covered, lways maintaining a sorted sublist at the beginning of oru collection of our list, anything new we encounter we jsut sort it\n",
    "- shift everything in the sorted list until we find the place of new addition\n",
    "- most intuitive to her, the other ones rather untuitive\n",
    "- code:\n",
    "    - can always start from the end rather than beginning, vice versa\n",
    "    - starting form the beginning\n",
    "    - current value and its position\n",
    "    - while previous elemetn is larger than current value, we move shift this element current element move it to further grab current value and start looking backwars and anything that is larger we move it further, once we encounter that is smaller than current value, then we have position where we should assign our value\n",
    "- again two loops, **still n squared** ASK CHAT GPT WHY, on the order of the length of the list\n",
    "- **performance: better often, better than selection sort, dont have swaps, no mutual assignment, often data we work with is partially sorted**\n",
    "- **merge sort is the one you will be using, using none of the one above**\n",
    "- **except for binary search, you will never have to write your own sorting algorithms**\n",
    "    - sometimes optimisations for certain data, but in general just covering hwo you learn to evaluate solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT\n",
    "\n",
    "- Outer Loop: The outer loop (for i in range(1, len(ls))) iterates through the list starting from the second element (index 1). For each element, it finds the correct position in the sorted part of the list (which is the portion before the current element).\n",
    "- Inner Loop (while loop): The inner loop (while pos > 0 and ls[pos - 1] > currentvalue) moves elements of the sorted part of the list to the right until it finds the correct position for the currentvalue (the element from the outer loop).\n",
    "- Inserting: Once the correct position is found, currentvalue is inserted into that position by setting ls[pos] = currentvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def insertion_sort(ls):\n",
    "    \"\"\"Assume ls is a list of elements that can be compared using >.\n",
    "    Sort ls in ascending order.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(1, len(ls)):\n",
    "        currentvalue = ls[i]\n",
    "        pos = i\n",
    "\n",
    "        while pos > 0 and ls[pos - 1] > currentvalue:\n",
    "            ls[pos] = ls[pos - 1]\n",
    "            pos -= 1\n",
    "\n",
    "        ls[pos] = currentvalue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Exercise 5: What is the time complexity of insertion sort?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Merge Sort\n",
    "\n",
    "*Example of divide and conquer strategy – break the problem into smaller pieces, solve the smaller pieces, and then reassemble to get the result*\n",
    "\n",
    "1. If the list has 0 or 1 elements, it is sorted\n",
    "2. If the list has more than 1 element, split the list in two and use merge sort on each\n",
    "3. Merge the results*\n",
    "\n",
    "\\* Merge by inspecting the first elements of the two lists and moving the smaller one to the end of the result list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- you dont have to write it youself, difficult\n",
    "- **this version is the one that .sort and sorted() use, thus they are O(n log n)**\n",
    "- recursive algorithm, example of divide and conquer strategy\n",
    "    - problem of sorting larger list is reduced by breaking the list down and then recombining them\n",
    "- recursive function\n",
    "    - more than one element\n",
    "    - split it int he middle and clal recursive on each sub list \n",
    "    because lsit is already sorted we dont have to compare anymore \n",
    "- this should be n log n? because that is the O for .sort and sorted(), this is what is implemented in python, they use merge sort\n",
    "- recursive tree, start from each leaf and reocmbine lsit together and order it, already sorted, recombiining is much easier, two sublists that are sorted, then start pickign by order from the two sub lists\n",
    "\n",
    "- **time complexity: O(n log n)**\n",
    "    - merge_sort() is called log n times\n",
    "        - splitting the list in half, log n steps, if we double the data, we add one more merge_sort() step\n",
    "    - merge() is on the order of n -> O(n)\n",
    "        - sequential loops, but not nested\n",
    "        - they touch each element\n",
    "\n",
    "\n",
    "\n",
    "    - //2 merge sort is called log n times. at every step splitting list in half, this is log n steps\n",
    "    - merge() is on the order of n, we have sequential loops, another loop here and there but all of these, they look at data we have and touch them but they are linear, touch elements multiple times within each sub list, touching them again ,but repeated loops rather than scaled loops adn they repeat log n times and thus n log n\n",
    "\n",
    "- **you dont have to write this, cannot do better than sort(), dont have to write any of this ever**\n",
    "- **but possible you might get question about this for data science jobs ,interview, how much you have covered, good to have some basic understanding of this, go to visualisation and study a bit, get intuition, with recursion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Merge Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def merge_sort(ls):\n",
    "    \"\"\"Assume ls is a list. \n",
    "    Return a new sorted list with same elements as ls.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(ls) <= 1:\n",
    "        return ls[:]\n",
    "    else:\n",
    "        middle = len(ls)//2\n",
    "        left = merge_sort(ls[:middle])\n",
    "        right = merge_sort(ls[middle:])\n",
    "        return merge(left, right) # calling merge on the result, it recombines these sorted lists\n",
    "    \n",
    "    \n",
    "def merge(left, right):\n",
    "    \"\"\"Assume left and right are sorted lists.\n",
    "    Return a new sorted list containing the same elements as (left + right).\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    i, j = 0, 0 # keep track where we are on the right and on the left list, keep goign until one of the list depletes\n",
    "    # Inspect the first items of the two lists and append the smaller one to results\n",
    "    while i < len(left) and j < len(right):\n",
    "        if left[i] < right[j]:\n",
    "            result.append(left[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            result.append(right[j])\n",
    "            j += 1\n",
    "    # Append any remaining items\n",
    "    while i < len(left):\n",
    "        result.append(left[i])\n",
    "        i += 1\n",
    "    while j < len(right):\n",
    "        result.append(right[j])\n",
    "        j += 1\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### The time and space complexity of merge sort\n",
    "* The time complexity of merge sort is $O(n \\log n)$. It takes $O(\\log n)$ splits and each of them requires a merge which is $O(n)$. In a merge, each item in the list will eventually be processed and placed on the sorted list, so it will take $n$ operations to get a list of size $n$\n",
    "* The space complexity is $O(n)$, as the algorithm copies the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hashing\n",
    "\n",
    "![Hashing](figs/hashing.jpg \"Hashing\")\n",
    "\n",
    "* A **hash table** is a collection of items that are stored in a way that makes them easy to find later\n",
    "* The goal is to design a hash table that allows us to search on the order of $O(1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hash Table \n",
    "\n",
    "![Empty hash table](figs/hash_table_empty.png \"Empty hash table\")\n",
    "\n",
    "* This hash table has length 10 and is currently empty\n",
    "* Slots are named with integers starting at 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- need a hash function that determines how the elements are positioned within the hash table\n",
    "- regardless how large your collection is, still O(1)\n",
    "    - opation of the hash function is constant look up time\n",
    "    - ideally one mathematical operation to find the element in the slot where it should be. It if is not there, then it is not in the list (have to look in the other items if we do linear probing or have to do linear search through the slot if chaining)\n",
    "    - looking up key in dict is constant look up time, same for sets because the key is hashed\n",
    "        - gets the key wehre it should be in memory and returns the value\n",
    "- You want to come up with a hash table that \n",
    "    - (1) minimises the number of collisions because the number of collisions increases the look up time. \n",
    "        - Have to use linear search within that slot with chaining approach (get from constant to linear time). We also do not wnat a complex hash function that is computationally intensive. \n",
    "    - (2) The second thing we want to do is to distribute the data as evenly as possible. Because you can minimise the number of collisions by having an infinitely large hash table. But then blocked a lot of memory. Want uniformly distributed hash table, all data is mapped uniquely without too many empty spots. \n",
    "    - Want to get as much variability without repeating values\n",
    "- Collisions are bound to happen given how simple our hash function is but we also dont want a very computationally demanding hash function\n",
    "    - modulo operator almost always used in hash functions because it ensures that each value will be allocated a slot that is contained within the hash table\n",
    "- common: modulo\n",
    "    - any answer we get is within range of possible values\n",
    "    - remainder cannot be larger than the whole part\n",
    "- is 22 in my data, use hash function, see whether it is in slot 2?\n",
    "- look up time is O(1)\n",
    "    - regardless of how large your table is, always dividing same numbers, some more operations depending on hash functions\n",
    "    - this is how lists and dict are implemented in python:\n",
    "        - common pytho methods: looking up a key in a dict is, whether my key is in dict, this is constant look up time, the key is hashed, instead of searching sequentially, gets the place where it should be in memory and checks whether it is there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The **hash function** defines how you map an item to its rightful slot\n",
    "    * For example, consider **the remainder method**, `i % h`, where `h` is the size of the hash table\n",
    "        * We need to store `20`, `22`, `34`, `45`, `117`\n",
    "        * `20 % 10 = 0`\n",
    "        * `22 % 10 = 2`\n",
    "        * `34 % 10 = 4`\n",
    "        * `45 % 10 = 5`\n",
    "        * `117 % 10 = 7`\n",
    "    \n",
    "![Hash table with items](figs/hash_table_filled.png \"Hash table with items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hash Table Collisions\n",
    "\n",
    "A **collision** occurs when more than one item maps to the same slot\n",
    "\n",
    "![Hash table with collision](figs/hash_table_collision.png \"Hash table with collision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we want to come up with hash function that minimises the number of collisions, collisions increase look up time, have to use linear search within that slot to look whether the item is there\n",
    "- want to distribute data as much as possible, can avoid collisions by having large table but have blocked large memory, want nice uniformely distributed, uniquely with not too many empty spots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The goal is to create a hash function that **minimizes the number of collisions, is easy to compute, and evenly distributes the items in the hash table**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hash Functions\n",
    "\n",
    "* The **remainder method** \n",
    "    * Guarantees that the result is within the range of slot names\n",
    "    * Because of this, the modulo arithmetic is typically present in some form in all hash functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The **folding method** \n",
    "    * Divide the item into equal-size pieces and add them to get the hash value; then use `%`\n",
    "    * E.g. 04/12/2017 = 04 + 12 + 20 +17 = 53 % 10 = 3 (if table length is 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The **mid-square method** \n",
    "    * Square the item and then extract some portion of the resulting digits to get the hash value; then use `%`\n",
    "    * E.g. 77 = 77^2 = 5929 = 92 % 10 = 2 (if table length is 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remainder method: almost always present in any hash function out there, guaranteees that any slot iwthin size of hash table\n",
    "- if data in date format, cannot divide it, have to transform it in some kind of way, for dates not all values are allowed, go beyond reasonable data we get ... what did she say here \n",
    "- folding method one way to do this \n",
    "- **get as much variability without repeating values that is the goal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hash Functions for Strings \n",
    "\n",
    "* Map each character to an ordinal value and sum them to get the hash value; then use `%`\n",
    "* E.g. 'cat' = ord('c') + ord('a') + ord('t') = 99 + 97 + 116 = 312 % 10 = 2 (if table length is 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MY472: every character in computer has unique O representation, unique code\n",
    "    - function in python called ord() that gives you the numeric part of any unique code incoded character\n",
    "- many anagrams in English, this method would suggest that anagrams would go to the same slot, thus way too many collisions\n",
    "    - words are limited by what we pronounce, there are syllables that are always together, thus a lot of similarity vs uniformely distributed data\n",
    "    - we want more variability in our data, thus weigh their unicode value by their position\n",
    "\n",
    "\n",
    "- unique code has numeric part which is unique\n",
    "- ord() gives oyu the numeric part of any character\n",
    "- take numeric part for eachc h\n",
    "- anagrams, thus way too many collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function ord in module builtins:\n",
      "\n",
      "ord(c, /)\n",
      "    Return the Unicode code point for a one-character string.\n",
      "\n",
      "99 97 116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "help(ord)\n",
    "print(ord('c'), ord('a'), ord('t'))\n",
    "\n",
    "# takes the numeric part of each character in the string, sums it and divides it by the table size\n",
    "def hash(string, table_size):\n",
    "    summ = sum([ord(i) for i in string])\n",
    "    return summ % table_size\n",
    "\n",
    "hash('cat', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The problem is that anagrams will always map to the same slot\n",
    "* One way to fix this is to use the position of the character as a weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 6: Hash Functions for Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n"
     ]
    }
   ],
   "source": [
    "# Rewrite the hash function below to mutliply the ordinal value \n",
    "# for each character by the position of the character\n",
    "\n",
    "def hash(string, table_size):\n",
    "    # summ = sum([ord(i) for i in string])\n",
    "    # enumerate() gives you both the index and the element in a sequence\n",
    "    summ = sum(([(i + 1) * ord(char) for i, char in enumerate(string)]))\n",
    "    return summ % table_size\n",
    "\n",
    "print(hash('cloud', 10), hash('could', 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resolving Collisions\n",
    " \n",
    "* Rehashing\n",
    "* Chaining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sometimes there will be collisions and these are ways to resolve that \n",
    "- restrictions on how large hash table can be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rehashing\n",
    "\n",
    "* If a collision occurs, place item into the next available empty slot (starting from the beginnning, if necessary)\n",
    "* When searching, continue **probing** until item is found or until you encounter an empty slot\n",
    "* `rehash(pos) = (pos + skip) % table_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rehashing: instead of chaining, put it into the next available empty slot\n",
    "    - you do increase the look up time a bit but at least data spread out \n",
    "    - guarantees that elements are evenly distributed (BUT: in the book it said if you always take the next available slot, then Klumpen/ clumps, chunks will form)\n",
    "    - will slightly increase look up time due to probing\n",
    "        - have estimated location, if this location already occupied, put it in the next skip slot away if that one is empty\n",
    "        - when rehasing, have to account for this skip\n",
    "        - is 12 in my table? use hash function to say it should be in position 2 but it is not there, then check next available position\n",
    "            - if you dont find it, then go to the next available position until you encounter element or EMPTY SLOT\n",
    "                - if you encounter an empty slot, it means that the element is not in the table, either you find the element or you find empty slot and that means the element is not in the table\n",
    "- +3 probing or quadratic probing\n",
    "\n",
    "\n",
    "\n",
    "- will slightly increase look up time because you have to do probing\n",
    "- once you encounter empty lsot when seaching, either oyu find it or empty spot that means the elemetn is not in the table\n",
    "- spread data as wide as possible but in systematic way so that you can look for the elements mroe easily see what she said here\n",
    "- rehashing: do increase look p time but spread it out and not many slots \n",
    "\n",
    "- chaining: put element in the same slot but then you have to use linear search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Linear probing** (`skip = 1`)\n",
    "\n",
    "![Linear probing for collisions](figs/collision_linear_probing.png \"Linear probing for collisions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Other variants include **plus 3 probing** (`skip = 3`) and **quadratic probing** (`skip = 1, 4, 9, 16, ...`)\n",
    "        \n",
    "![Plus 3 probing for collisions](figs/collision_plus3_probing.png \"Plus 3 probing for collisions\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Chaining\n",
    "\n",
    "* If a collision occurs, still place item into the proper slot\n",
    "* When searching, use the hash function to generate the slot and then use a searching technique to find the item in the collection at that slot\n",
    "\n",
    "![Hash table with collision](figs/hash_table_collision.png \"Hash table with collision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chaining\n",
    "    - keep adding elements at this memory slot\n",
    "    - now use linear searching, go through each element in that slot, if it is not there, then it is not in the tale\n",
    "    - both of these carry a bit of an overhead\n",
    "- idea of hashing is constant look up time but in practice a bit more complicated\n",
    "- look up time depends on load factor lambda\n",
    "    - size of data divided by size of hash table\n",
    "    - if twice as much data, lambda values * 2, more collisions\n",
    "    - trade off between memory and look up time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* In theory, hashing provides $O(1)$ searching\n",
    "* In practice, due to collisions, the runtime depends on the **load factor**, or $\\lambda = \\frac{n}{h}$, where $n$ is the number of items and $h$ is the size of the hash table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Searching and Sorting Algorithms\n",
    "\n",
    "* The best sorting algorithm is $O(n \\log n)$\n",
    "* To search an ordered list, use binary search, which is $O(\\log n)$ \n",
    "* To search an unordered list, the best we can do is $O(n)$\n",
    "* In practice, sorting and binary search is not always faster than linear search\n",
    "* Use hash tables for O(1) searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- main goal of today: practice order of growth analysis and searching and sorting\n",
    "- best sorting is n log n\n",
    "    - ways to optimise it for different types of data, but in terms of order of growth it does not get better than this\n",
    "- for ordered list, binary search way more efficient than linear search\n",
    "- for most applications, you dont have to worry about this, unless doing lots of searches\n",
    "- when not orderd, O(n) is the best we can do\n",
    "- can always sort and then do binary search but in practice might not be worht it\n",
    "    - depends on ow large the data is and how often you need to search\n",
    "    - linear search might be good enough\n",
    "- if lots of searches, you should opt for hash table\n",
    "    - the part where you might have to implement it yourself\n",
    "    - no universal way to do this\n",
    "    - dict and set already use hashing, can rely on what python does but if outside of pyhton, have to implement your hash table\n",
    "- functional programming in python, extension of week 8 (R), how to do that in python, options for optimising runtime in seminar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "-------\n",
    "\n",
    "* **Lab**: **Problem Set 5**, functional programming in Python\n",
    "* **Next week**: Basic tree and graph algorithms, course summary, guidance for final project"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
